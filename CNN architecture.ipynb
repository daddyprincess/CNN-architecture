{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0845b41f-fad2-4119-ad23-0994d7acbe0f",
   "metadata": {},
   "source": [
    "## Topic: Understanding Pooling and Padding in CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72721afe-711c-48e3-8c49-105f5019cd1e",
   "metadata": {},
   "source": [
    "### 1. Describe the purpose and benefits of pooling in CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254a9cc-aabc-4ce1-b0bc-a4b819c3fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pooling, also known as subsampling or downsampling, is a critical operation in Convolutional Neural Networks (CNNs) that\n",
    "serves several important purposes and offers various benefits. Pooling is typically applied after convolutional layers and \n",
    "is used to reduce the spatial dimensions of feature maps while retaining the most important information. There are two common \n",
    "types of pooling: max pooling and average pooling.\n",
    "\n",
    "Purpose of Pooling:\n",
    "\n",
    "1.Dimensionality Reduction: One of the primary purposes of pooling is to reduce the spatial dimensions of the feature maps.\n",
    " This helps in lowering the computational complexity of the network and reducing the risk of overfitting. Smaller feature \n",
    "maps require fewer parameters in subsequent layers, making the network more manageable.\n",
    "\n",
    "2.Translation Invariance: Pooling helps to achieve translation invariance in feature detection. This means that the network\n",
    " can recognize features in different parts of the input image, regardless of their exact position. Pooling helps the network\n",
    "focus on the presence of specific features rather than their precise location within the receptive field.\n",
    "\n",
    "3.Feature Selection: Pooling retains the most important features while discarding less relevant or redundant information. \n",
    " This ensures that only the strongest signals are propagated through the network, improving the network's ability to learn\n",
    "and generalize from data.\n",
    "\n",
    "4.Computational Efficiency: By reducing the spatial dimensions, pooling reduces the computational workload in subsequent \n",
    " layers, leading to faster training and inference times. This is especially important for deep CNNs, where the number of\n",
    "parameters and computations can be substantial.\n",
    "\n",
    "Benefits of Pooling:\n",
    "\n",
    "1.Robustness to Spatial Variations: Pooling makes CNNs robust to small spatial variations and distortions in the input data.\n",
    " This is particularly useful in tasks like image classification, where the object of interest can appear in different parts\n",
    "of the image.\n",
    "\n",
    "2.Improved Generalization: Pooling helps prevent overfitting by reducing the spatial resolution of feature maps, which can\n",
    " lead to a more generalized and better-performing model. It focuses on the key information needed for classification.\n",
    "\n",
    "3.Reduced Memory Requirements: Smaller feature maps occupy less memory, making it possible to train and deploy larger and\n",
    " deeper networks within the available computational resources.\n",
    "\n",
    "4.Increased Invariance: Pooling increases the network's ability to recognize features regardless of their exact position in \n",
    " the input, which is crucial for detecting objects, patterns, or features in various orientations and scales.\n",
    "\n",
    "5.Speed and Efficiency: Smaller feature maps from pooling layers result in faster training and inference times, which is\n",
    " crucial for real-time applications and large-scale deployments.\n",
    "\n",
    "While pooling has many benefits, it's important to note that it does result in some loss of spatial information, and more\n",
    "recent developments in CNN architectures (such as the use of global average pooling or attention mechanisms) aim to mitigate\n",
    "these limitations while still reaping the benefits of pooling. The choice of pooling technique and its parameters may vary\n",
    "depending on the specific task and architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faefe65-736e-445e-a978-8078d10fe58a",
   "metadata": {},
   "source": [
    "### 2.Explain the diffecence between min pooling and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a193c17-7862-46c3-8696-32d417237fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Max pooling and min pooling are two different techniques used in Convolutional Neural Networks (CNNs) for feature map \n",
    "downsampling. They are similar in operation but differ in how they select values to retain from the input region. Let's \n",
    "explore the differences between max pooling and min pooling:\n",
    "\n",
    "Max Pooling:\n",
    "\n",
    "1.Operation: Max pooling involves dividing the input feature map into non-overlapping regions (typically small squares or\n",
    "  rectangles) and selecting the maximum value from each region to form the output feature map. The maximum value represents\n",
    "the most significant feature in that region.\n",
    "\n",
    "2.Advantage: Max pooling is good at capturing the most salient features in the input, making it suitable for tasks where you \n",
    " want to highlight the presence of particular features or patterns. It is particularly effective in object recognition and \n",
    "image classification tasks.\n",
    "\n",
    "3.Invariance: Max pooling provides translation invariance, meaning it can recognize the same feature regardless of its exact\n",
    "  position within the region.\n",
    "\n",
    "4.Common Use: Max pooling is the more commonly used form of pooling in CNNs, and it is used in many popular CNN\n",
    "  architectures, including LeNet, AlexNet, and VGG.\n",
    "\n",
    "Min Pooling:\n",
    "\n",
    "1.Operation: Min pooling is less common than max pooling. It involves dividing the input feature map into non-overlapping\n",
    "  regions, similar to max pooling. However, instead of selecting the maximum value, it selects the minimum value from each \n",
    "region to form the output feature map.\n",
    "\n",
    "2.Advantage: Min pooling may be used in cases where you want to focus on the least intense features or the absence of \n",
    " certain characteristics. It can be useful in scenarios where the presence of particular patterns in the data is essential.\n",
    "\n",
    "3.Invariance: Like max pooling, min pooling also provides translation invariance.\n",
    "\n",
    "4.Use Cases: Min pooling is not as widely used as max pooling in typical CNN architectures and applications. Its use is more\n",
    " specialized and depends on the specific requirements of the task.\n",
    "\n",
    "In summary, the key difference between max pooling and min pooling lies in the operation of selecting values from the input\n",
    "regions. Max pooling selects the maximum value, emphasizing the most prominent features, while min pooling selects the\n",
    "minimum value, which might be useful in scenarios where you want to focus on less intense or absent features. Max pooling is\n",
    "more commonly used in CNNs and is suitable for a wide range of tasks, while min pooling is less common and is typically used\n",
    "in more specialized applications. The choice between them depends on the specific needs of the problem you are trying to\n",
    "solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfbc64a-4b92-48df-a969-983a2572207b",
   "metadata": {},
   "source": [
    "### 3.Discuss the concept of padding in CNN and its signijicance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fff1db-17e3-4f1c-93bf-189760325d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Padding in Convolutional Neural Networks (CNNs) is a technique used to control the spatial dimensions of the output \n",
    "feature maps after applying convolutional and pooling operations. It involves adding extra, often zero-valued, pixels\n",
    "around the input data before convolution or pooling. Padding is a critical component in CNNs, and it serves several\n",
    "important purposes:\n",
    "\n",
    "1.Control Output Size:\n",
    "    When you apply convolutional or pooling operations, the spatial dimensions of the feature maps tend to decrease. \n",
    "    If these dimensions shrink too quickly, you may lose valuable spatial information. Padding helps control this \n",
    "    reduction in size and ensures that the output feature maps have the desired dimensions, which can be particularly\n",
    "    important in various applications.\n",
    "\n",
    "2.Preserving Spatial Information:\n",
    "    Without padding, when a filter moves across the input image, it can only \"see\" the center pixels effectively, and\n",
    "    the edge information may be lost. Padding allows the filters to take into account the pixels near the edges, \n",
    "    preserving spatial information and helping in detecting features that are closer to the image boundaries.\n",
    "\n",
    "3.Better Handling of Stride:\n",
    "    Padding allows you to apply convolution with a larger stride while maintaining the size of the output feature maps. \n",
    "    Larger strides can speed up the computation and reduce the spatial dimensions more rapidly. Padding can mitigate\n",
    "    the reduction in the spatial dimension and enable you to extract features at different scales.\n",
    "\n",
    "There are two common types of padding in CNNs:\n",
    "\n",
    "1.Valid (No Padding):\n",
    "    In this mode, no padding is added to the input image, and the convolutional or pooling operation is applied only\n",
    "    to the pixels that completely fit within the input. As a result, the output feature maps will have smaller spatial\n",
    "    dimensions than the input.\n",
    "\n",
    "2.Same (Zero Padding):\n",
    "    In \"same\" padding, padding is added to the input image such that the output feature maps have the same spatial \n",
    "    dimensions as the input. Typically, an equal amount of padding is added to all sides of the input, and zero values\n",
    "    are often used for the padded pixels.\n",
    "\n",
    "The choice of padding type (valid or same) depends on the specific application and network architecture. For instance, \n",
    "\"same\" padding is often used when you want to preserve the spatial dimensions, and \"valid\" padding is used when you\n",
    "don't mind the size reduction and want to focus on extracting the most critical features.\n",
    "\n",
    "In summary, padding is a fundamental concept in CNNs that helps control the size of output feature maps, preserves\n",
    "spatial information, and enhances the network's ability to detect features across different scales and positions within\n",
    "the input data. It is a crucial tool for designing effective convolutional neural networks for image processing and\n",
    "other spatial data analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d7a88f-301c-4112-8350-1216b11970e1",
   "metadata": {},
   "source": [
    "### 4.Compace and contrast zero-padding and valid-padding in terms oj their effects on the output featuce map size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed93b7f-1ff3-4afe-8b16-dec7ebe800f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zero-padding and valid-padding are two common techniques used to control the size of the output feature maps in\n",
    "Convolutional Neural Networks (CNNs). They have contrasting effects on the spatial dimensions of the output feature \n",
    "maps:\n",
    "\n",
    "1.Zero-Padding:\n",
    "\n",
    "    ~Zero-padding, often referred to as \"same\" padding, involves adding extra pixels (usually zeros) around the input \n",
    "     image before applying convolution or pooling operations.\n",
    "    ~The primary goal of zero-padding is to ensure that the output feature maps have the same spatial dimensions as \n",
    "     the input, or as closely as possible. In other words, it aims to maintain the size of the feature maps.\n",
    "    ~Zero-padding is useful when you want to preserve spatial information and ensure that the output feature maps cover\n",
    "     the entire input area without losing edge information.\n",
    "    ~With zero-padding, the output size depends on the size of the kernel/filter and the stride used. It's generally\n",
    "     given by the formula:\n",
    "    ~Output Size = ((Input Size - Filter Size + 2 * Padding) / Stride) + 1.\n",
    "    \n",
    "2.Valid-Padding:\n",
    "\n",
    "    ~Valid-padding, also known as \"no padding,\" involves applying convolution or pooling operations without any \n",
    "     additional padding around the input image.\n",
    "    ~The primary goal of valid-padding is to allow the network to focus on the central regions of the input while\n",
    "     letting the spatial dimensions of the feature maps naturally decrease during the convolution or pooling process.\n",
    "    ~Valid-padding is often used when you don't need to preserve the exact size of the feature maps, and you are \n",
    "     willing to accept a reduction in spatial dimensions for computational or architectural reasons.\n",
    "    ~With valid-padding, the output size is smaller than the input size and is given by the formula:\n",
    "        ~Output Size = ((Input Size - Filter Size) / Stride) + 1\n",
    "        \n",
    "In summary, the key difference between zero-padding and valid-padding is in their effects on the output feature map \n",
    "size:\n",
    "\n",
    "    ~Zero-padding maintains or increases the spatial dimensions of the output feature maps to match the input, \n",
    "     ensuring that edge information is preserved.\n",
    "\n",
    "    ~Valid-padding results in smaller spatial dimensions for the output feature maps, potentially reducing the\n",
    "     feature map size compared to the input, as it doesn't add any extra pixels around the input.\n",
    "\n",
    "The choice between these padding methods depends on the specific requirements of your task and the desired\n",
    "architectural characteristics of your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51e5cd-f5df-4234-8434-52d4ccc2c649",
   "metadata": {},
   "source": [
    "## Topic: Exploring LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6782c-96f6-46a4-b85a-3eaf4afe6b41",
   "metadata": {},
   "source": [
    "### 1.Provide a brief overview of LeNet-5 architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913d8d8c-0db7-4173-a5df-7d8a4e307441",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet-5 is a classic Convolutional Neural Network (CNN) architecture developed by Yann LeCun, Leon Bottou, Yoshua\n",
    "Bengio, and Patrick Haffner in 1998. It played a pivotal role in popularizing CNNs and was one of the early successes\n",
    "in the field of deep learning. LeNet-5 was primarily designed for handwritten digit recognition, which is a common \n",
    "task in the context of digitizing documents and recognizing zip codes on letters. Here's a brief overview of the \n",
    "LeNet-5 architecture:\n",
    "\n",
    "1.Input Layer:\n",
    "\n",
    "    ~LeNet-5 takes a 32x32 pixel grayscale image as input.\n",
    "2.Convolutional Layers:\n",
    "\n",
    "    ~LeNet-5 consists of two convolutional layers, each followed by a subsampling (pooling) layer.\n",
    "    ~The first convolutional layer uses a 5x5 kernel and has 6 feature maps. It applies a \"tanh\" activation function.\n",
    "    ~The first subsampling layer is average pooling with a 2x2 window and a stride of 2.\n",
    "    ~The second convolutional layer uses a 5x5 kernel and has 16 feature maps. It also applies a \"tanh\" activation\n",
    "     function.\n",
    "    ~The second subsampling layer is again average pooling with a 2x2 window and a stride of 2.\n",
    "    \n",
    "3.Fully Connected Layers:\n",
    "\n",
    "    ~After the convolutional and subsampling layers, LeNet-5 has three fully connected layers.\n",
    "    ~The first fully connected layer has 120 units and uses a \"tanh\" activation function.\n",
    "    ~The second fully connected layer has 84 units and also uses a \"tanh\" activation function.\n",
    "    ~The final fully connected layer consists of 10 units, corresponding to the 10 possible digits (0-9) for digit\n",
    "     recognition tasks.\n",
    "        \n",
    "4.Output Layer:\n",
    "\n",
    "    ~The output layer employs a softmax activation function to produce probability scores for each of the 10 possible\n",
    "    digits.\n",
    "    \n",
    "5.Training:\n",
    "\n",
    "    ~LeNet-5 was typically trained using the gradient descent optimization algorithm.\n",
    "    ~It used the backpropagation algorithm to update the weights and biases in the network.\n",
    "    \n",
    "LeNet-5 made several important contributions to the field of deep learning and computer vision:\n",
    "\n",
    "    ~It introduced the concept of using a series of convolutional and pooling layers, which is now a fundamental\n",
    "     building block of modern CNN architectures.\n",
    "    ~LeNet-5 demonstrated the effectiveness of using the \"tanh\" activation function in hidden layers.\n",
    "    ~The architecture was designed to handle 3D input volumes (width, height, depth), which was a key innovation for\n",
    "     image data.\n",
    "        \n",
    "While LeNet-5 is relatively simple compared to modern CNN architectures, it laid the foundation for more complex\n",
    "networks, such as AlexNet, VGG, and the deep neural networks that dominate image recognition tasks today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0031ad8-2e2b-492e-8bfc-90f77df1fd2a",
   "metadata": {},
   "source": [
    "### 2.Describe the key components of LeNet-5 and their respective purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757abe41-ee25-4834-9fe8-19205b10000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet-5 is a classic Convolutional Neural Network (CNN) architecture, and it comprises several key components, each\n",
    "with its own specific purpose in the network. Here's a description of the primary components of LeNet-5 and their\n",
    "respective purposes:\n",
    "\n",
    "1.Input Layer:\n",
    "\n",
    "    ~Purpose: The input layer accepts grayscale images of size 32x32 pixels. It acts as the entry point for the data\n",
    "     into the network. In the context of LeNet-5, it takes the input image and feeds it into the subsequent layers for\n",
    "    feature extraction and classification.\n",
    "    \n",
    "2.Convolutional Layers:\n",
    "\n",
    "    ~Purpose: The convolutional layers are responsible for feature extraction from the input image. LeNet-5 has two\n",
    "     convolutional layers.\n",
    "    ~First Convolutional Layer: It uses 6 5x5 kernels to create six feature maps, each representing different low-\n",
    "     level features of the input image, such as edges and basic textures.\n",
    "    ~Second Convolutional Layer: This layer applies 16 5x5 kernels to the feature maps from the previous layer,\n",
    "     generating higher-level feature maps that capture more complex patterns and relationships in the input.\n",
    "        \n",
    "3.Activation Functions:\n",
    "\n",
    "    ~Purpose: After each convolutional layer, a hyperbolic tangent (tanh) activation function is applied. The tanh\n",
    "     activation introduces non-linearity into the network, allowing it to model complex relationships within the \n",
    "    features.\n",
    "    \n",
    "4.Subsampling (Pooling) Layers:\n",
    "\n",
    "    ~Purpose: The subsampling (or pooling) layers are used to reduce the spatial dimensions of the feature maps, which\n",
    "     helps in retaining important information while reducing the computational load.\n",
    "    ~The first subsampling layer performs average pooling with a 2x2 window and a stride of 2.\n",
    "    ~The second subsampling layer also performs average pooling with the same configuration, further reducing the \n",
    "     feature map size.\n",
    "        \n",
    "5.Fully Connected Layers:\n",
    "\n",
    "    ~Purpose: The fully connected layers are responsible for high-level feature representation and classification.\n",
    "    ~First Fully Connected Layer: It has 120 units and is connected to the second subsampling layer. This layer \n",
    "     extracts intricate features from the feature maps produced by the convolutional layers.\n",
    "    ~Second Fully Connected Layer: With 84 units, this layer continues to learn more abstract features from the \n",
    "     previous layer's output.\n",
    "    ~Final Fully Connected Layer: This layer consists of 10 units, corresponding to the 10 possible digit classes\n",
    "     (0-9). It produces the final class scores using a softmax activation function, indicating the network's\n",
    "    confidence in predicting each digit.\n",
    "    \n",
    "6.Output Layer:\n",
    "\n",
    "    ~Purpose: The output layer uses the softmax activation function to convert the class scores produced by the final \n",
    "     fully connected layer into probability distributions over the 10 digit classes. This enables LeNet-5 to make\n",
    "    digit classification predictions.\n",
    "    \n",
    "7.Training:\n",
    "\n",
    "    ~Purpose: LeNet-5 is trained using supervised learning, with labeled data to update the weights and biases in the\n",
    "     network. The network's objective is to minimize the classification error during training, typically using gradient\n",
    "    descent or a similar optimization algorithm.\n",
    "    \n",
    "In summary, LeNet-5 is a pioneering CNN architecture that introduced the concept of convolutional and pooling layers \n",
    "for feature extraction, followed by fully connected layers for classification. Its key components work together to\n",
    "extract features from input images and make accurate digit classification predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11954f1-3b04-4800-ac40-b0c8bd5df268",
   "metadata": {},
   "source": [
    "### 3.Discuss the advantages and limitations of LeNet-5 in the context of image classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd6740-e76a-4b62-9e09-b608daa59833",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet-5, as a pioneering Convolutional Neural Network (CNN) architecture, has several advantages and limitations when \n",
    "applied to image classification tasks:\n",
    "\n",
    "Advantages:\n",
    "\n",
    "1.Effective Feature Extraction: LeNet-5 is capable of effective feature extraction due to its convolutional layers.\n",
    "  These layers learn low-level features like edges and gradually build up to higher-level features, enabling it to\n",
    "capture meaningful patterns in images.\n",
    "\n",
    "2.Translation Invariance: Convolutional layers with weight sharing provide translation invariance, meaning the network\n",
    "  can recognize patterns regardless of their exact position in the input image. This is a crucial property for image \n",
    "classification.\n",
    "\n",
    "3.Architectural Simplicity: LeNet-5 has a relatively simple architecture compared to modern CNNs. This simplicity\n",
    "  makes it easy to understand and implement. It also has fewer parameters, which can be advantageous in terms of \n",
    "training speed and model size.\n",
    "\n",
    "4.Historical Significance: LeNet-5 played a pivotal role in popularizing CNNs and establishing their effectiveness in\n",
    "  computer vision tasks. It served as a foundation for subsequent, more complex CNN architectures.\n",
    "\n",
    "5.Suitable for Handwritten Digit Recognition: LeNet-5 was specifically designed for tasks like handwritten digit \n",
    "  recognition, where it performs well. Its architectural choices are well-suited to this type of task.\n",
    "\n",
    "Limitations:\n",
    "\n",
    "1.Limited Depth: LeNet-5 is relatively shallow compared to more modern CNN architectures. Deeper networks often have\n",
    "  a greater capacity to learn complex hierarchical features, which can be beneficial for tasks with intricate patterns.\n",
    "\n",
    "2.Small Input Size: LeNet-5 was designed for 32x32 pixel grayscale images. This limited input size might not be\n",
    " sufficient for tasks involving high-resolution images, where larger networks with more complex architectures are\n",
    "needed.\n",
    "\n",
    "3.Lack of Generalization: LeNet-5's architecture was optimized for digit recognition and may not generalize well to\n",
    "  more diverse image datasets with different types of objects and scenes. It might require substantial modifications\n",
    "to perform well on such tasks.\n",
    "\n",
    "4.Activation Function: LeNet-5 uses the hyperbolic tangent (tanh) activation function, which can suffer from the\n",
    "  vanishing gradient problem. Modern architectures often use rectified linear units (ReLUs) that alleviate this issue.\n",
    "\n",
    "5.Training Data Requirements: Like many deep learning models, LeNet-5 requires a substantial amount of labeled \n",
    "  training data to perform well. It may not work effectively with small datasets.\n",
    "\n",
    "6.Performance Compared to Modern CNNs: While LeNet-5 was groundbreaking in its time, modern CNN architectures, such \n",
    "  as ResNet, Inception, and VGG, have surpassed its performance in image classification tasks. These newer \n",
    "architectures have larger and more complex structures, which are better suited to challenging datasets like ImageNet.\n",
    "\n",
    "In summary, LeNet-5 is a historically important CNN architecture with a simple and effective design for its time,\n",
    "making it suitable for specific image classification tasks, particularly handwritten digit recognition. However, its\n",
    "limitations become more apparent when applied to broader and more complex image classification challenges, where more\n",
    "modern and sophisticated CNN architectures are preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40398b8a-dd9c-4ad4-abb8-e2cb30d850ed",
   "metadata": {},
   "source": [
    "### 4.Implement LeNet-5 using a deep learning framework of your choice (e.g., TensorFlow, PyTorch) and train it on a publicly available dataset (e.g., MNIST). Evaluate its performance and provide insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec67406-a78a-4e6f-b83e-3ea8f9020b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "# Normalize and preprocess the data\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Build the LeNet-5 model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Layer 1: Convolutional Layer\n",
    "model.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional Layer\n",
    "model.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output for fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Layer 3: Fully Connected Layer\n",
    "model.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Layer 4: Fully Connected Layer\n",
    "model.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Output Layer: Fully Connected Layer with 10 units for 10 classes\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0048b31-e53c-4bef-98da-10ca07ebe65e",
   "metadata": {},
   "source": [
    "### TOPIC: Analyzing AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d36b4-ad34-4007-a360-e26ba3ccd407",
   "metadata": {},
   "source": [
    "### 1.Present an overview of the AlexNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7eea1-1af1-4341-912b-940ea6fa63d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet is a pioneering deep convolutional neural network (CNN) architecture developed by Alex Krizhevsky, Ilya\n",
    "Sutskever, and Geoffrey Hinton in 2012. It gained widespread recognition for its performance in the ImageNet Large\n",
    "Scale Visual Recognition Challenge (ILSVRC) in 2012, significantly advancing the state of the art in image\n",
    "classification. Here's an overview of the AlexNet architecture:\n",
    "\n",
    "1. Input Layer (Image Data):\n",
    "\n",
    "    ~AlexNet takes RGB color images as input. In the ILSVRC competition, the input size is 224x224x3.\n",
    "    \n",
    "2. Convolutional Layers:\n",
    "\n",
    "    ~AlexNet comprises five convolutional layers. The first convolutional layer uses an 11x11 kernel with a stride of \n",
    "     4, while the subsequent convolutional layers use 3x3 kernels.\n",
    "    ~The number of filters in these layers progressively increases, starting from 96 in the first layer, then 256,\n",
    "     384, 384, and 256 in the subsequent layers.\n",
    "    ~Rectified Linear Unit (ReLU) activation functions are applied after each convolutional layer, introducing non-\n",
    "     linearity.\n",
    "        \n",
    "3. Max-Pooling Layers:\n",
    "\n",
    "    ~After some of the convolutional layers, max-pooling layers are used to reduce the spatial dimensions of the \n",
    "     feature maps and down-sample the data.\n",
    "    ~Pooling layers are applied with a 3x3 window and a stride of 2.\n",
    "    \n",
    "4. Local Response Normalization (LRN) Layer:\n",
    "\n",
    "    ~LRN layers are used to enhance the contrast between features within the same feature map. They help neurons to\n",
    "     respond to more varied inputs.\n",
    "        \n",
    "5. Fully Connected Layers:\n",
    "\n",
    "    ~After the convolutional and pooling layers, AlexNet includes three fully connected layers.\n",
    "    ~The first fully connected layer has 4096 units, followed by a second fully connected layer also with 4096 units.\n",
    "    ~The final fully connected layer has 1000 units, corresponding to the 1000 classes in the ImageNet dataset used\n",
    "     in the ILSVRC competition.\n",
    "    ~The fully connected layers are followed by ReLU activation functions, dropout layers for regularization, and the \n",
    "     output layer.\n",
    "        \n",
    "6. Output Layer:\n",
    "\n",
    "    ~The output layer is a fully connected layer with 1000 units, each corresponding to one of the 1000 possible \n",
    "     ImageNet classes.\n",
    "    ~The output is typically passed through a softmax activation function to produce class probabilities.\n",
    "    \n",
    "7. Training and Optimization:\n",
    "\n",
    "    ~AlexNet was trained using the stochastic gradient descent (SGD) optimization algorithm.\n",
    "    ~Data augmentation techniques, such as random cropping and horizontal flipping, were used during training to\n",
    "     increase the model's robustness.\n",
    "        \n",
    "8. Innovations and Impact:\n",
    "\n",
    "    ~AlexNet made several key innovations, including the use of ReLU activation functions, dropout for regularization,\n",
    "     and deep convolutional neural networks.\n",
    "    ~It significantly reduced the error rates on image classification tasks and set the stage for the development of\n",
    "     more sophisticated deep learning models.\n",
    "        \n",
    "AlexNet's success in the ILSVRC competition marked a turning point in the field of computer vision and played a crucial\n",
    "role in popularizing deep learning for image analysis tasks. It demonstrated the power of deep CNNs and paved the way\n",
    "for the development of subsequent, even more complex CNN architectures for various applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbe063e-bef7-43ce-9ada-69a6698158ad",
   "metadata": {},
   "source": [
    "### 2.Explain the architectural innovations introduced in AlexNet that contributed to its breakthrough performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b6136-50f8-40df-a60b-73c58942dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet, which achieved a breakthrough in image classification performance in the 2012 ImageNet Large Scale Visual\n",
    "Recognition Challenge (ILSVRC), introduced several architectural innovations that played a crucial role in its success.\n",
    "These innovations significantly contributed to its superior performance compared to previous models. Here are the key\n",
    "architectural innovations introduced in AlexNet:\n",
    "\n",
    "1.Deep Convolutional Neural Network (CNN):\n",
    "\n",
    "    ~AlexNet was one of the first deep CNN architectures for image classification. It consisted of multiple stacked \n",
    "     convolutional layers, which allowed it to learn hierarchical features from the input data.\n",
    "    ~The use of deep networks enabled the model to capture complex and abstract features, which was essential for\n",
    "     classifying a large number of object categories.\n",
    "        \n",
    "2.Rectified Linear Unit (ReLU) Activation Functions:\n",
    "\n",
    "    ~AlexNet used Rectified Linear Units (ReLU) as the activation function after each convolutional and fully \n",
    "     connected layer.\n",
    "    ~ReLU activation functions helped mitigate the vanishing gradient problem and accelerated training by introducing\n",
    "     non-linearity.\n",
    "        \n",
    "3.Local Response Normalization (LRN) Layers:\n",
    "\n",
    "    ~AlexNet included LRN layers after certain convolutional layers. LRN layers enhance the contrast between feature \n",
    "     responses within the same feature map.\n",
    "    ~This normalization technique improved the model's ability to recognize more varied patterns and features.\n",
    "    \n",
    "4.Large Filter Sizes and Multiple Filters:\n",
    "\n",
    "    ~The first convolutional layer in AlexNet used an 11x11 filter size with a stride of 4, resulting in a larger\n",
    "     receptive field.\n",
    "    ~The model employed multiple filters (96 in the first layer), which allowed it to learn a wide range of low-level\n",
    "     features.\n",
    "        \n",
    "5.Max-Pooling Layers:\n",
    "\n",
    "    ~Max-pooling layers with a 3x3 window and a stride of 2 were used to down-sample the feature maps, reducing the\n",
    "     spatial dimensions while preserving important features.\n",
    "    ~Max-pooling helped the model focus on more discriminative information.\n",
    "    \n",
    "6.Fully Connected Layers with Dropout:\n",
    "\n",
    "    ~AlexNet featured three fully connected layers, the last of which had 1000 output units corresponding to the \n",
    "     1000 ImageNet classes.\n",
    "    ~To prevent overfitting, dropout layers were applied after the fully connected layers. Dropout randomly\n",
    "     deactivates a fraction of neurons during training.\n",
    "        \n",
    "7.Parallel GPU Training:\n",
    "\n",
    "    ~Training deep networks like AlexNet was computationally intensive. To accelerate training, the authors used two\n",
    "     GPUs in parallel, a relatively novel approach at the time.\n",
    "    ~This parallel processing allowed them to train the deep network more efficiently and led to faster convergence.\n",
    "    \n",
    "8.Data Augmentation:\n",
    "\n",
    "    ~Data augmentation techniques were employed during training to increase the model's robustness. Techniques like\n",
    "     random cropping and horizontal flipping were used to create variations of the training data.\n",
    "        \n",
    "9.Competition Setting:\n",
    "\n",
    "    ~The use of AlexNet in the ILSVRC competition also contributed to its breakthrough. The competition itself \n",
    "     fostered the development of increasingly sophisticated CNN architectures, as researchers aimed to outperform \n",
    "    each other.\n",
    "    \n",
    "These architectural innovations collectively enabled AlexNet to significantly reduce error rates in image\n",
    "classification and played a pivotal role in advancing the field of deep learning and computer vision. The success of \n",
    "AlexNet demonstrated the potential of deep CNNs and set the stage for the development of even more complex and \n",
    "effective neural network architectures for various applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211196fe-e65a-47dc-aa93-263cf745a2be",
   "metadata": {},
   "source": [
    "### 3.Discuss the role of convolutional layers, pooling layers, and jully connected layers in AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26627b2-b101-42b0-90f6-afaad78462ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "In AlexNet, the role of convolutional layers, pooling layers, and fully connected layers is crucial for feature\n",
    "extraction, spatial reduction, and classification, respectively. Here's a detailed explanation of the roles of each \n",
    "of these layers in the AlexNet architecture:\n",
    "\n",
    "1.Convolutional Layers:\n",
    "\n",
    "    ~Feature Extraction: The convolutional layers in AlexNet are responsible for feature extraction from the input\n",
    "     image. These layers use convolutional operations with learnable filters (kernels) to detect various features such\n",
    "    as edges, textures, and more complex patterns within the input data.\n",
    "    ~Hierarchical Feature Learning: The stacked convolutional layers learn hierarchical features. The early layers \n",
    "     capture simple features, like edges and corners, while deeper layers extract more complex and abstract features.\n",
    "    ~Parameter Sharing: Convolutional layers use parameter sharing, meaning that the same set of filters is applied to \n",
    "     different parts of the input, which allows the network to recognize these features across the entire image.\n",
    "        \n",
    "2.Pooling Layers (Max-Pooling):\n",
    "\n",
    "    ~Spatial Reduction: The pooling layers in AlexNet are used to reduce the spatial dimensions of the feature maps\n",
    "     produced by the convolutional layers. This spatial reduction helps decrease the computational load and control\n",
    "    overfitting.\n",
    "    ~Feature Selection: Max-pooling is employed to select the most important features within each pooling window. By\n",
    "    taking the maximum value from a region, the model preserves the most salient features and suppresses less relevant \n",
    "    information.\n",
    "    ~Translation Invariance: Pooling layers contribute to the translation invariance property of CNNs, meaning the\n",
    "    network can recognize features irrespective of their exact location in the input.\n",
    "3.Fully Connected Layers:\n",
    "\n",
    "    ~High-Level Feature Representation: The fully connected layers in AlexNet are responsible for high-level feature\n",
    "    representation and classification. After the convolutional and pooling layers, the feature maps are flattened and \n",
    "    fed into these fully connected layers.\n",
    "    ~Complex Pattern Recognition: The fully connected layers capture complex patterns and relationships among the \n",
    "    learned features, making them capable of distinguishing among a wide range of object categories.\n",
    "    ~Final Classification: The output layer of the fully connected layers provides the final classification of the\n",
    "    input data. In AlexNet, this layer has 1000 units, corresponding to the 1000 ImageNet classes. The softmax\n",
    "    activation function converts the output into class probabilities.\n",
    "    \n",
    "In summary, convolutional layers play a pivotal role in feature extraction, pooling layers contribute to spatial\n",
    "reduction and feature selection, and fully connected layers handle high-level feature representation and classification \n",
    "in the AlexNet architecture. These layers work together to enable the model to recognize and classify objects within\n",
    "images with high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68066014-f9c4-45fc-8811-cb2722e7c3d7",
   "metadata": {},
   "source": [
    "### 4.Implement AlexNet using a deep learning framework of your choice and evaluate its performance on a dataset oj your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ad007-0feb-4c6e-99c5-c99fe247407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# Define the AlexNet architecture\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = AlexNet(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Training\n",
    "for epoch in range(10):  # Loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "# Testing\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfb2b7-3234-47dc-9e51-df2527a146f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1fdb15-13e7-4e49-9523-83268b197830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
